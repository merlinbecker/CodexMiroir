# In-Memory Cache Analyse: Vergleich der Architektur-AnsÃ¤tze

**Datum:** 2025-10-11  
**Status:** Analyse  
**Kontext:** Evaluation ob In-Memory Cache sinnvoller wÃ¤re als aktueller Blob-Storage-basierter Cache

---

## ğŸ“‹ Zusammenfassung

### Aktueller Ansatz: **Blob-Storage-basierter Cache**
- Tasks werden in Azure Blob Storage gespeichert (`raw/userId/tasks/*.md`)
- Timeline wird als JSON-Artefakt gecacht (`artifacts/userId/timeline_<version>.json`)
- Cache wird bei jeder Aktion (create/update/complete) invalidiert
- Git-Sync lÃ¤uft asynchron Ã¼ber Webhooks oder manuelle Syncs

### Vorgeschlagener Ansatz: **In-Memory Cache mit Shared Memory**
- Timeline fÃ¼r eingeloggte User in-memory (gemeinsamer Speicher Ã¼ber Functions)
- Operationen (create/update/complete) arbeiten auf Memory-Cache
- Bei Operationen: Storage-Save + optional Git-Sync
- Bei fehlendem Memory-Cache: Rebuild from Storage + optional Sync

---

## ğŸ—ï¸ Architektur-Details

### Aktueller Ansatz (Blob-Storage-basiert)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HTTP Request   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  renderCodex    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Blob Storage    â”‚
â”‚  (Function)     â”‚      â”‚  raw/tasks/*.md  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  artifacts/*.jsonâ”‚
         â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Build Timeline â”‚
â”‚  (on cache miss)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Return JSON    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Operations: create/update/complete
â”œâ”€â–¶ Save to Blob Storage (raw/tasks/*.md)
â”œâ”€â–¶ Invalidate Cache (delete artifacts/*.json)
â””â”€â–¶ Optional: Sync to GitHub
```

**Cache-Strategie:**
- Version basiert auf: `baseVersion_YYYYMMDD_HH`
- `baseVersion` aus `state/cacheVersion.txt` (invalidiert bei Actions)
- StÃ¼ndliche Auto-Invalidierung durch Stunden-Suffix
- Cache HIT: Timeline aus `artifacts/userId/timeline_*.json` laden
- Cache MISS: Timeline neu bauen, als Artefakt speichern

### Vorgeschlagener Ansatz (In-Memory)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HTTP Request   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  renderCodex    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Shared Memory   â”‚
â”‚  (Function)     â”‚      â”‚  Map<userId, {   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    timeline,     â”‚
         â”‚               â”‚    tasks[]       â”‚
         â”‚               â”‚  }>              â”‚
         â–¼               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory HIT?    â”‚
â”‚  Yes: return    â”‚
â”‚  No: rebuild    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Operations: create/update/complete
â”œâ”€â–¶ Update Memory Cache (Timeline + Tasks Array)
â”œâ”€â–¶ Save to Blob Storage (raw/tasks/*.md)
â””â”€â–¶ Optional: Sync to GitHub

Rebuild Trigger:
- User not in Memory
- Manual refresh
- Cold start (Function restart)
```

**Cache-Strategie:**
- Global `Map<userId, TimelineData>` Ã¼ber alle Functions
- Keine Persistierung des Caches (nur in-memory)
- Bei Cold Start oder fehlendem Entry: Rebuild from Storage
- Tasks-Array im Memory fÃ¼r schnelle Operationen

---

## âš–ï¸ Vor- und Nachteile

### Aktueller Ansatz: Blob-Storage-basiert

#### âœ… Vorteile

1. **Persistenz & Konsistenz**
   - Cache Ã¼berlebt Function-Restarts (kein Cold-Start-Problem)
   - Konsistente Daten Ã¼ber alle Function-Instanzen hinweg
   - Kein State-Management zwischen Instanzen nÃ¶tig

2. **Skalierbarkeit**
   - Azure Functions skaliert horizontal automatisch
   - Jede Instanz kann unabhÃ¤ngig auf Blob Storage zugreifen
   - Keine Shared-Memory-Probleme bei Multi-Instance-Deployment

3. **Audit & Debugging**
   - Cache-Artefakte sind inspizierbar (`artifacts/*.json`)
   - Blob Storage bietet Versioning/Soft-Delete (optional)
   - Einfaches Debugging: Cache-Files direkt im Portal ansehen

4. **Git-Sync-KompatibilitÃ¤t**
   - Tasks in Blob Storage spiegeln Git-Repo (Source of Truth)
   - Einfache Reconciliation zwischen Storage und Git
   - Webhook-Sync kann direkt Storage aktualisieren

5. **Cache-Invalidierung ist explizit**
   - Klare Semantik: Aktion â†’ Invalidierung â†’ Rebuild
   - Zeitbasierte Invalidierung (Stunden-Suffix) funktioniert gut
   - Keine Race-Conditions zwischen Reads/Writes

#### âŒ Nachteile

1. **Latenz bei Cache-Miss**
   - Timeline-Rebuild dauert (alle Tasks lesen + parsen + platzieren)
   - Blob Storage I/O ist langsamer als In-Memory
   - Bei vielen Users: Cache-Misses nach jeder Invalidierung

2. **ÃœbermÃ¤ÃŸige Invalidierung**
   - Jede Task-Operation invalidiert ALLE User-Caches
   - StÃ¼ndliche Auto-Invalidierung auch bei InaktivitÃ¤t
   - Viele Rebuilds, obwohl sich nichts geÃ¤ndert hat (andere User)

3. **Storage-Kosten**
   - Cache-Artefakte belegen Speicher
   - Bei vielen Usern: Viele Cache-Files (`artifacts/userId/timeline_*.json`)
   - Alte Cache-Versions werden nicht automatisch gelÃ¶scht

4. **KomplexitÃ¤t bei Cache-Versions-Management**
   - `cacheVersion.txt` + Stunden-Suffix = komplexe Versionierung
   - Alte Artefakte mÃ¼ssen manuell cleaned werden
   - Cache-Lookup sucht ALLE `artifacts/userId/timeline_*` (ineffizient)

---

### Vorgeschlagener Ansatz: In-Memory Cache

#### âœ… Vorteile

1. **Extrem schnelle Reads**
   - Timeline direkt aus Memory (keine I/O)
   - Operationen (get/update) in Mikrosekunden statt Millisekunden
   - Perfekt fÃ¼r hohe Read-Frequenz (renderCodex wird oft aufgerufen)

2. **Einfachere Architektur**
   - Keine Cache-Versions-Verwaltung nÃ¶tig
   - Keine Artefakte im Blob Storage
   - Logik: "Ist im Memory? Ja â†’ return, Nein â†’ build + cache"

3. **Geringere Blob-Storage-Kosten**
   - Keine Cache-Artefakte (`artifacts/` wird nicht benÃ¶tigt)
   - Nur rohe Task-Files (`raw/tasks/*.md`) im Storage
   - Weniger Storage-Transaktionen

4. **Automatische User-Isolation**
   - Jeder User hat seinen eigenen Memory-Entry
   - Operationen eines Users beeinflussen andere nicht
   - Kein globaler Cache-Invalidierungs-Overhead

5. **NatÃ¼rliche "Cache-Eviction"**
   - Cold Start â†’ Memory leer â†’ Rebuild nur fÃ¼r aktive User
   - Inaktive User belegen keinen Memory (werden nicht rebuilt)
   - LRU-Eviction mÃ¶glich (Ã¤lteste Timeline aus Memory entfernen)

#### âŒ Nachteile

1. **Cold-Start-Problem**
   - Bei Function-Restart: ALLE User-Timelines sind weg
   - Erste Requests nach Cold-Start sind langsam (Rebuild)
   - Azure Functions kÃ¶nnen jederzeit recycled werden (unvorhersehbar)

2. **Multi-Instance-Probleme**
   - Bei horizontaler Skalierung: Mehrere Function-Instanzen
   - Jede Instanz hat eigenen Memory â†’ Inkonsistenz zwischen Instanzen
   - Load Balancer routet Requests unterschiedlich â†’ User trifft verschiedene Instanzen
   - **LÃ¶sung nÃ¶tig:** Sticky Sessions oder Distributed Cache (Redis)

3. **Memory-Limits**
   - Azure Functions haben Memory-Limits (abhÃ¤ngig von Plan)
   - Viele aktive User â†’ groÃŸe Memory-Consumption
   - Bei 1000 Usern Ã¡ 50 KB Timeline = 50 MB Memory nur fÃ¼r Caches
   - Consumption-Plan: 1,5 GB Memory-Limit gesamt

4. **Komplexe Invalidierungs-Logik**
   - Wann aus Memory entfernen? (TTL? LRU? Manual?)
   - Zeitbasierte Invalidierung schwieriger (muss in-memory getracked werden)
   - Race-Conditions: Read wÃ¤hrend Write (Locking nÃ¶tig?)

5. **Kein Audit-Trail**
   - Cache-State ist flÃ¼chtig (keine Persistierung)
   - Debugging schwieriger: "Warum zeigt User X falsche Daten?"
   - Keine History: Kann nicht nachvollziehen, wann Cache invalidiert wurde

6. **Git-Sync-KomplexitÃ¤t**
   - Memory ist nicht Git-synced
   - Webhook-Update muss Memory invalidieren (nicht nur Storage)
   - Race-Condition: Webhook kommt wÃ¤hrend Operation an
   - **Beispiel:** User updated Task â†’ Memory + Storage update â†’ Webhook Ã¼berschreibt Storage â†’ Memory ist stale

---

## ğŸ”¬ Kritische Szenarien

### Szenario 1: Multi-Instance-Deployment

**Problem:**
```
Function Instance A: User1's Timeline in Memory (Task 0001 = "offen")
Function Instance B: User1's Timeline in Memory (Task 0001 = "offen")

User1 markiert Task 0001 als abgeschlossen:
â†’ Request trifft Instance A
â†’ Instance A: Memory Update (Task 0001 = "abgeschlossen")
â†’ Instance A: Storage Update

NÃ¤chster Request von User1:
â†’ Request trifft Instance B (Load Balancer!)
â†’ Instance B: Liefert ALTE Timeline aus Memory (Task 0001 = "offen")
```

**LÃ¶sung:**
- Distributed Cache (z.B. Azure Redis Cache) statt lokalem Memory
- Sticky Sessions (Azure Front Door / API Management)
- Memory nur als "Hot Cache", Storage als "Source of Truth" + Invalidierung

**Aktueller Ansatz:**
- Kein Problem, da Blob Storage von allen Instanzen geteilt wird
- Cache-Artefakte sind konsistent Ã¼ber alle Instanzen

### Szenario 2: Cold Start nach InaktivitÃ¤t

**Problem:**
```
User1 war 30 Minuten inaktiv
â†’ Function wurde recycled (Azure Consumption Plan)
â†’ Memory ist leer

User1 Ã¶ffnet App:
â†’ renderCodex: Memory MISS
â†’ Rebuild from Storage (alle Tasks lesen + parsen + Timeline bauen)
â†’ 2-5 Sekunden Latenz
```

**Aktueller Ansatz:**
- Cache-Artefakte im Blob Storage Ã¼berlebt Cold Start
- Erste Request nach Cold Start: Cache HIT (schnell)

### Szenario 3: Git-Webhook + gleichzeitige User-Operation

**Problem:**
```
T0: User1 updated Task 0005 (Memory + Storage)
T1: GitHub Webhook kommt an (Push von anderem GerÃ¤t)
    â†’ Webhook Ã¼berschreibt ALL Tasks in Storage (fullSync)
    â†’ Memory ist jetzt stale (hat alte Version von Task 0005)
T2: User1 rendert Timeline
    â†’ Memory HIT (zeigt veraltete Daten!)
```

**LÃ¶sung:**
- Webhook muss Memory invalidieren (schwierig bei Multi-Instance)
- Alternative: Memory-TTL (z.B. 5 Minuten), dann automatisch rebuild

**Aktueller Ansatz:**
- Webhook invalidiert Cache (delete artifacts)
- NÃ¤chster Request: Cache MISS â†’ Rebuild from Storage (aktuell)

---

## ğŸ“Š Performance-Vergleich (geschÃ¤tzt)

### Blob-Storage-basiert (aktuell)

| Operation | Latenz | Storage I/O | Skalierbarkeit |
|-----------|--------|-------------|----------------|
| Timeline Render (Cache HIT) | ~100ms | 1 read (JSON) | â­â­â­â­â­ Excellent |
| Timeline Render (Cache MISS) | ~2-5s | 50-500 reads (alle Tasks) | â­â­â­â­ Good |
| Task Create | ~500ms | 2 writes (Task + invalidate) | â­â­â­â­â­ Excellent |
| Task Complete | ~500ms | 2 writes (Task + invalidate) | â­â­â­â­â­ Excellent |
| Cold Start Impact | â­â­â­â­â­ None | Cache Ã¼berlebt Cold Start | - |

### In-Memory (vorgeschlagen)

| Operation | Latenz | Storage I/O | Skalierbarkeit |
|-----------|--------|-------------|----------------|
| Timeline Render (Memory HIT) | ~1-5ms | 0 | â­â­ Requires Redis |
| Timeline Render (Memory MISS) | ~2-5s | 50-500 reads (rebuild) | â­â­â­â­ Good |
| Task Create | ~50ms | 1 write (Task) | â­â­ Requires Redis |
| Task Complete | ~50ms | 1 write (Task) | â­â­ Requires Redis |
| Cold Start Impact | â­â­ Severe | Alle User mÃ¼ssen rebuilden | - |

**Hinweis:** In-Memory ohne Distributed Cache (Redis) ist **nicht produktionsfÃ¤hig** bei Multi-Instance.

---

## ğŸ’¡ Empfehlung: Hybrid-Ansatz

### Option 1: **Optimierter Blob-Storage-Cache (Empfohlen)**

**Verbesserungen am aktuellen System:**

1. **User-spezifische Cache-Invalidierung**
   ```javascript
   // Aktuell: Invalidiere ALL Caches
   await invalidateCache(); // LÃ¶scht artifacts/*
   
   // Besser: Invalidiere nur betroffenen User
   await invalidateCacheForUser(userId); // LÃ¶scht nur artifacts/userId/*
   ```

2. **TTL-basierte Invalidierung (statt stÃ¼ndlich)**
   ```javascript
   // Statt: cacheVersion = "baseVersion_YYYYMMDD_HH"
   // Besser: TTL in Artefakt-Metadata
   
   async function getCachedTimeline(userId) {
     const cache = await getTextBlob(`artifacts/${userId}/timeline.json`);
     if (!cache) return null;
     
     const data = JSON.parse(cache);
     const age = Date.now() - new Date(data.cacheCreatedAt).getTime();
     const TTL = 15 * 60 * 1000; // 15 Minuten
     
     if (age > TTL) {
       return null; // Cache abgelaufen
     }
     
     return data;
   }
   ```

3. **Lazy Invalidierung (nur bei Bedarf lÃ¶schen)**
   ```javascript
   // Statt: Bei Operation alle Artefakte lÃ¶schen
   // Besser: Flag "dirty" setzen, beim nÃ¤chsten Read neu bauen
   
   await putTextBlob(`state/${userId}/cacheValid.txt`, "false");
   ```

**Vorteile:**
- âœ… BehÃ¤lt alle Vorteile des aktuellen Systems (Persistenz, Skalierbarkeit)
- âœ… Eliminiert Hauptnachteile (Ã¼bermÃ¤ÃŸige Invalidierung, User-Isolation)
- âœ… Keine neue Infrastruktur nÃ¶tig (Redis)
- âœ… Einfach zu implementieren

### Option 2: **In-Memory mit Redis (fÃ¼r spÃ¤ter)**

Falls Performance kritisch wird (>1000 aktive User):

1. **Azure Redis Cache** als Distributed Cache
   ```javascript
   const redis = require('redis');
   const client = redis.createClient({
     url: process.env.AZURE_REDIS_CONNECTION_STRING
   });
   
   async function getTimeline(userId) {
     // 1. Versuche Redis
     const cached = await client.get(`timeline:${userId}`);
     if (cached) return JSON.parse(cached);
     
     // 2. Rebuild from Storage
     const timeline = await buildTimeline(userId);
     
     // 3. Cache in Redis (TTL 15 Min)
     await client.setEx(`timeline:${userId}`, 900, JSON.stringify(timeline));
     
     return timeline;
   }
   ```

2. **Invalidierung via Redis**
   ```javascript
   async function invalidateUserCache(userId) {
     await client.del(`timeline:${userId}`);
   }
   ```

**Vorteile:**
- âœ… Extrem schnell (1-5ms Latency)
- âœ… Multi-Instance-safe (shared Redis)
- âœ… TTL + LRU Eviction automatisch

**Nachteile:**
- âŒ ZusÃ¤tzliche Kosten (~â‚¬60/Monat fÃ¼r Basic Redis)
- âŒ ZusÃ¤tzliche KomplexitÃ¤t
- âŒ Mehr Infrastruktur zu managen

---

## ğŸ¯ Finale Bewertung

### FÃ¼r CodexMiroir (aktueller Stand):

| Kriterium | Blob-Storage (aktuell) | In-Memory (vorgeschlagen) | Hybrid (empfohlen) |
|-----------|------------------------|---------------------------|---------------------|
| **Performance (Read)** | â­â­â­â­ 100ms | â­â­â­â­â­ 1-5ms | â­â­â­â­â­ 1-5ms |
| **Performance (Cold Start)** | â­â­â­â­â­ Keine Impact | â­â­ Alle rebuilden | â­â­â­â­â­ Keine Impact |
| **Skalierbarkeit** | â­â­â­â­â­ Excellent | â­â­ Needs Redis | â­â­â­â­â­ Excellent |
| **Konsistenz** | â­â­â­â­â­ Storage = Truth | â­â­â­ Multi-Instance Issues | â­â­â­â­â­ Storage = Truth |
| **KomplexitÃ¤t** | â­â­â­ Mittel | â­â­ Hoch (Race Conditions) | â­â­â­â­ Niedrig |
| **Kosten** | â­â­â­â­ Niedrig | â­â­ Redis ~â‚¬60/Monat | â­â­â­â­ Niedrig |
| **Debugging** | â­â­â­â­â­ Artefakte inspizierbar | â­â­ FlÃ¼chtig | â­â­â­â­â­ Artefakte inspizierbar |

### ğŸ“Œ Empfehlung: **Hybrid-Ansatz (Option 1)**

**Kurz:**
- Behalte **Blob-Storage-Cache** als Basis
- Optimiere **User-spezifische Invalidierung**
- FÃ¼ge **TTL-basierte Cache-PrÃ¼fung** hinzu
- Optional: **Local In-Memory Layer** (pro Function-Instance) als "Hot Cache"

**Implementierung:**
```javascript
// Dual-Layer Cache: Local Memory (hot) + Blob Storage (persistent)

const localCache = new Map(); // Pro Function-Instance

async function getTimeline(userId) {
  // Layer 1: Local Memory (1-5ms)
  const local = localCache.get(userId);
  if (local && local.validUntil > Date.now()) {
    return local.timeline;
  }
  
  // Layer 2: Blob Storage (100ms)
  const blob = await getTextBlob(`artifacts/${userId}/timeline.json`);
  if (blob) {
    const data = JSON.parse(blob);
    const age = Date.now() - new Date(data.cacheCreatedAt).getTime();
    if (age < 15 * 60 * 1000) { // 15 Min TTL
      // Cache lokal fÃ¼r 5 Minuten
      localCache.set(userId, {
        timeline: data,
        validUntil: Date.now() + 5 * 60 * 1000
      });
      return data;
    }
  }
  
  // Layer 3: Rebuild from Storage (2-5s)
  const timeline = await buildTimeline(userId);
  
  // Cache in Blob + Local
  await putTextBlob(
    `artifacts/${userId}/timeline.json`, 
    JSON.stringify(timeline)
  );
  localCache.set(userId, {
    timeline,
    validUntil: Date.now() + 5 * 60 * 1000
  });
  
  return timeline;
}
```

**Vorteile dieses Ansatzes:**
- âœ… Beste Performance: Local Cache (1-5ms) fÃ¼r wiederholte Requests
- âœ… Multi-Instance-safe: Blob Storage als Truth
- âœ… Cold-Start-safe: Blob Storage Ã¼berlebt Function-Restarts
- âœ… Keine zusÃ¤tzlichen Kosten (Redis)
- âœ… User-Isolation: Jeder User hat eigenen Cache
- âœ… Automatisches TTL-Management
- âœ… Einfach zu implementieren

---

## ğŸš€ NÃ¤chste Schritte (wenn Hybrid-Ansatz gewÃ¤hlt)

1. **Refactor `storage.js`**
   - `invalidateCacheForUser(userId)` statt `invalidateCache()`
   - TTL-Check in `getCachedTimeline(userId)`

2. **Refactor `renderCodex.js`**
   - Dual-Layer Cache implementieren (Local Map + Blob)
   - User-spezifische Cache-Keys (`artifacts/${userId}/timeline.json`)

3. **Refactor Operations** (`createTask`, `updateTask`, `completeTask`)
   - Invalidiere nur betroffenen User-Cache
   - Setze "dirty"-Flag statt Delete

4. **Testing**
   - Multi-User-Tests (User A Ã¤ndert Task, User B sieht es nicht)
   - Cold-Start-Tests (Function restart, Cache Ã¼berlebt)
   - Performance-Tests (Cache HIT vs MISS Latency)

---

## ğŸ“š Fazit

**Frage:** Ist In-Memory Cache sinnvoller?

**Antwort:** 
- **Nein, nicht als reiner In-Memory-Ansatz** (ohne Redis)
  - Zu viele Probleme: Multi-Instance, Cold Start, Race Conditions
  - BenÃ¶tigt Redis fÃ¼r Production â†’ ZusÃ¤tzliche Kosten + KomplexitÃ¤t
  
- **Ja, als Hybrid-Ansatz** (Local Memory + Blob Storage)
  - Bestes aus beiden Welten: Speed + Persistenz + Einfachheit
  - Minimale Ã„nderungen am aktuellen System
  - Keine neuen Dependencies
  - **Empfohlen!**

**TL;DR:** Optimiere den aktuellen Blob-Storage-Cache mit User-spezifischer Invalidierung und optionalem Local-Memory-Layer. Verzichte auf reinen In-Memory-Ansatz ohne Distributed Cache.
